package spark

import org.apache.spark.sql.SparkSession
import util.Random

object GeospacialDemo {

  def run_prog = {

    val spark = SparkSession.builder
      .appName("My Spark GeoSpatial Application") // optional and will be autogenerated if not specified
      .master("local[*]") // avoid hardcoding the deployment environment
      .getOrCreate

    System.setProperty("hadoop.home.dir", "E:\\Hadoop\\HADOOP_HOME\\bin")

    val geo_locs = spark.read.option("header", "true").option("delimiter", ",").csv("src/repository/geospace_all.csv")
    //      .toDF("trip_id", "timestamp", "lat", "lon")

    println("Count=> " + geo_locs.count())
    geo_locs.show(10)

  }
}
